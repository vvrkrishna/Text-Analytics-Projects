{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2], dtype=int64), array([ 4160, 19145,  1430], dtype=int64))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading and preprocessing data\n",
    "import pandas as pd, numpy as np, re\n",
    "df = pd.read_csv('D:/USF/Text Analytics/Class Presentations and Python Code Files/Week10-Deep Learning and Miscellanous Topics/Hate_Speech.csv', encoding ='latin1')\n",
    "df.dtypes\n",
    "df = df[['tweet', 'label']]\n",
    "df.shape\n",
    "np.unique(df['label'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install contractions\n",
    "import contractions # Note: contractions is a library for converting words like \"I'm\" to \"I am\"\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words(\"english\")\n",
    "stop_words.extend([\"&amp;\", \"&gt;\", \"&lt;\", \"RT\"])\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_tweets = []\n",
    "for t in df['tweet']:\n",
    "    t = t.translate(t.maketrans('\\n\\t\\r', '   '))\n",
    "    t = contractions.fix(t)\n",
    "    t = re.sub(r'http\\S+', ' ', t)              # Drop URLs\n",
    "    t = re.sub(r'@\\S+', ' ', t)                 # Drop Twitter handles\n",
    "    t = re.sub(r'#\\S+', ' ', t)                 # Drop hashtags\n",
    "    t = re.sub(r'[^a-zA-Z0-9\\s]', '', t)        \n",
    "    t = re.sub(' +', ' ', t)                    # Multiple spaces to single space\n",
    "    words = t.lower().split()\n",
    "    words = [w for w in words if len(w)>2 and w not in stop_words]\n",
    "    words = [lemmatizer.lemmatize(w) for w in words]\n",
    "    t = ' '.join(words)\n",
    "    tokenized_tweets.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24711, 3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"tokens\"] = tokenized_tweets\n",
    "df['tokens'].replace('', np.nan, inplace=True)  # Drop rows with no tokens\n",
    "df.dropna(subset=['tokens'], inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2], dtype=int64), array([ 4152, 19134,  1425], dtype=int64))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['label'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18533, 3), (6178, 3))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train and test split with 80:20 ratio\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.25) \n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18533 rows as training data set and 6178 as testing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "# Define embedding dimensions: max sequence lengths, max number of words\n",
    "MAX_SEQ_LENGTH = 50        # If tweet seq length > MAX_SEQ_LENGTH, truncate; if less, pad with zeros.\n",
    "MAX_NB_WORDS = 20000       # If word count is exceeded, take most frequent words\n",
    "EMBEDDING_DIM = 100        \n",
    "import tensorflow as tf\n",
    " # Convert tweets to features using keras Tokenizer since keras cannot processor words\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS) \n",
    "tokenizer.fit_on_texts(train['tokens'])    \n",
    "train_sequences = tokenizer.texts_to_sequences(train['tokens'])\n",
    "test_sequences = tokenizer.texts_to_sequences(test['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[15, 6, 1543, 2],\n",
       " [703, 1],\n",
       " [7, 6, 65, 6685],\n",
       " [2993, 1681],\n",
       " [87, 1, 13, 4665, 80, 6686, 170],\n",
       " [134, 2594, 38, 42, 3, 9, 186, 80],\n",
       " [656, 6, 4666, 192],\n",
       " [745, 1149, 2595, 511, 2994, 101, 1, 387, 987, 49, 1226],\n",
       " [3, 39, 940, 218, 770, 310, 4667],\n",
       " [252, 988, 2, 497, 175],\n",
       " [6, 31, 88, 1],\n",
       " [1, 304, 3, 323, 4668, 6687, 2596, 311, 25],\n",
       " [2995, 3650, 295, 114, 812, 1150, 6688, 6689, 248, 771, 1422],\n",
       " [229, 173, 20, 77, 57, 202, 1, 388, 42, 223, 430, 9],\n",
       " [498, 389, 129, 2597],\n",
       " [41, 6690, 2598, 3651, 1318, 150, 404, 48, 13, 29, 3652],\n",
       " [219, 2, 17, 304, 538, 410, 582],\n",
       " [302, 5, 90, 525, 15, 5, 2996, 187, 138, 2997, 6, 2],\n",
       " [58, 1],\n",
       " [1423, 3, 4669, 269, 1, 6691, 941, 6692],\n",
       " [36, 112, 1042, 2599, 4670],\n",
       " [21, 379, 405, 4671, 1319, 1424, 6693, 1682, 71, 942, 3653],\n",
       " [2024, 102, 7, 1683, 4672, 115, 1],\n",
       " [1227, 346, 124, 564, 1151, 1151, 1684, 23, 564],\n",
       " [772, 4673, 2998, 4, 3654, 3655, 6694, 6695, 1685],\n",
       " [28, 423, 1, 6696, 355],\n",
       " [1152, 850, 1, 850, 87],\n",
       " [1686, 1, 4674, 6697],\n",
       " [371, 10, 3656, 6698, 81, 91, 6699, 894, 6700],\n",
       " [32, 1],\n",
       " [176, 4, 726, 1104, 68, 1, 1544, 123],\n",
       " [1, 28, 6701],\n",
       " [226, 1, 13, 363, 305],\n",
       " [463, 195, 8, 4, 3],\n",
       " [1320, 1545, 12, 6702, 6703, 130, 1687, 15, 1545, 82, 131, 2282, 3, 1, 2600],\n",
       " [6704, 390, 1105, 1228, 347, 92, 273, 634, 114, 727, 8, 220, 1229],\n",
       " [196, 19, 49, 23, 6705, 1425, 116],\n",
       " [9, 1426, 2601, 1, 83, 728, 36, 4675, 236, 4676, 388, 67, 1321],\n",
       " [4677, 2999, 4678, 3, 989, 3657, 4679, 372, 4680, 773, 4681, 2025, 3000, 306],\n",
       " [1, 69, 35, 48, 277, 615, 10, 704, 96],\n",
       " [2026, 6706, 484, 943],\n",
       " [2602, 15, 1427, 8, 50, 746, 1, 89, 3658, 40, 13, 774, 1322, 12],\n",
       " [155, 88, 2],\n",
       " [113, 199, 2027, 23, 705, 15, 2603, 813, 177],\n",
       " [85, 97, 1428, 1],\n",
       " [1688, 24, 442, 4, 245],\n",
       " [1, 6707, 254],\n",
       " [2, 171, 1323, 944],\n",
       " [35, 604, 39, 23],\n",
       " [3001, 676, 1106, 17, 188, 135, 1230, 2],\n",
       " [191, 1, 7, 443, 21, 67, 6708, 6709, 634, 80, 1],\n",
       " [371, 729, 851, 22, 464, 990, 391, 312, 3659, 2604],\n",
       " [147, 192, 1324, 1689, 895, 7, 2605, 5, 130, 485],\n",
       " [23, 1325, 1546, 2283, 1043, 6710],\n",
       " [616, 4682, 27, 16, 4683, 3002, 2606, 3660, 6711, 2028],\n",
       " [70, 102, 1, 4684, 944, 35, 131, 6712],\n",
       " [450, 1],\n",
       " [1044, 2029, 3003, 1, 392, 356, 317],\n",
       " [1690, 1326, 657, 115, 583, 208, 318, 42, 2607, 59, 11],\n",
       " [6713, 30, 6714, 249, 21, 123, 6715],\n",
       " [218, 6716, 1, 2030, 124, 617, 6717],\n",
       " [43, 5, 36, 43, 1, 1153, 124],\n",
       " [19, 6718, 30, 24, 4, 10, 3, 189],\n",
       " [204, 706, 6719],\n",
       " [190, 36, 1107, 2031, 1429, 11],\n",
       " [5, 364, 33, 1, 152, 6720, 5],\n",
       " [40, 618, 814, 2032, 172, 21, 209, 3004, 1, 181, 324],\n",
       " [6721, 53, 3005, 93, 8, 113, 3006, 416, 44, 6722, 70, 2284],\n",
       " [2, 1108, 1327, 4685, 2033, 2285, 2608, 1328, 181],\n",
       " [1, 14, 1, 1],\n",
       " [14, 64, 2034],\n",
       " [94, 318, 289, 6723, 2035, 348, 4686, 39, 171, 3007, 71],\n",
       " [82, 991, 707, 1, 393, 70, 747, 3, 219, 6, 815, 219],\n",
       " [53, 312],\n",
       " [3008, 3, 62, 619, 6724, 499, 1],\n",
       " [2036, 365, 5, 1547, 5, 8, 1, 1548, 132, 287, 5, 2286, 12],\n",
       " [1, 583, 2287, 4687, 4688, 1691, 319, 392, 31, 565, 15, 37, 8, 486],\n",
       " [487, 497, 103, 500, 19, 6725, 383, 3009, 100, 6726, 2, 8, 3010],\n",
       " [3661, 566, 1845, 90, 133, 852, 2594, 2],\n",
       " [775, 112, 290, 3011, 3662, 501, 3663, 2288, 6727, 21, 115, 237, 61, 62, 160],\n",
       " [6728, 6729, 6730, 2037, 2609, 776, 431, 4],\n",
       " [2029, 10, 12, 1692, 2610, 63, 97, 133, 310, 4, 108, 12, 2289],\n",
       " [4689, 1430, 17, 1431, 677, 9, 2, 72, 1431],\n",
       " [186, 478, 96, 248, 186, 1846, 1, 7],\n",
       " [1, 6731, 6732],\n",
       " [197, 172, 64, 539],\n",
       " [746, 2, 2611],\n",
       " [30, 28, 526],\n",
       " [1, 7, 278, 3664, 82, 411, 349],\n",
       " [6733, 21, 678, 3665, 75, 21, 47, 3665, 11, 15, 6],\n",
       " [37, 567, 71, 777, 59, 1109, 4690],\n",
       " [44, 90, 8, 1549, 21, 1, 2038],\n",
       " [2290, 2612, 157],\n",
       " [635, 50, 172, 13, 23, 3012, 465],\n",
       " [138, 288, 1],\n",
       " [18, 153, 255, 19, 16, 38],\n",
       " [94, 1, 853],\n",
       " [33, 1, 14, 9, 15, 41, 195, 60, 3, 232, 2291, 1, 992],\n",
       " [816, 1550, 11, 993],\n",
       " [33,\n",
       "  1231,\n",
       "  1,\n",
       "  3666,\n",
       "  854,\n",
       "  3,\n",
       "  6734,\n",
       "  6735,\n",
       "  6736,\n",
       "  1,\n",
       "  945,\n",
       "  36,\n",
       "  3013,\n",
       "  432,\n",
       "  1231,\n",
       "  3667],\n",
       " [26, 1, 323, 6737, 2292, 21],\n",
       " [9, 2],\n",
       " [174, 1847, 5, 464, 258, 1],\n",
       " [307, 778, 108, 3014, 2, 187],\n",
       " [102, 2039, 20, 64, 708, 210, 896, 636, 3015, 6738, 6739, 3668],\n",
       " [817, 10, 23],\n",
       " [679, 58, 705, 23, 2613, 3669, 4691, 2293, 6740, 6741, 2614, 35, 60, 1848],\n",
       " [1, 584, 779, 58, 20, 111],\n",
       " [2, 41, 22, 585, 12],\n",
       " [6742, 112, 50, 2615, 2616, 11, 60, 1551, 6743, 620],\n",
       " [6744, 1, 211, 994, 62, 279, 38],\n",
       " [114, 4692, 214, 313, 995],\n",
       " [50, 1, 34, 551, 451, 165, 1552, 6745, 202, 39],\n",
       " [79, 897, 288, 193, 310, 209, 1849, 452, 6746, 310, 54, 1849, 237],\n",
       " [540, 4, 3, 466, 3016],\n",
       " [200, 159, 43, 364, 6747],\n",
       " [2, 3670, 12],\n",
       " [21, 274, 680, 1045, 196, 242, 264, 1, 7, 193, 4693, 996],\n",
       " [27, 98, 3, 1, 703, 161, 1329, 212, 10, 586, 35, 6748, 113],\n",
       " [1, 709, 10],\n",
       " [78, 1330, 221, 106, 6749, 6750, 4694, 6751, 67, 76, 118, 855],\n",
       " [27, 2, 3671, 16, 453, 238, 119, 453, 2294],\n",
       " [2617, 37, 54, 1],\n",
       " [209, 275, 4695, 3672, 478, 4696],\n",
       " [1, 162, 2618, 3673, 4, 1693, 992],\n",
       " [302, 83, 10, 454, 1],\n",
       " [1],\n",
       " [1553, 34, 1, 1432, 3, 3017, 4697, 1318, 22, 6752, 1046, 6753],\n",
       " [148, 58, 2, 18, 327],\n",
       " [233, 7, 40, 406, 2295, 7, 1],\n",
       " [2619, 21, 26, 120, 3, 1, 551, 6754],\n",
       " [681, 818, 552, 16, 126, 2296, 710, 412, 224, 115, 11],\n",
       " [50, 637, 85, 36, 14, 55, 4, 280],\n",
       " [1694, 1433, 6755, 55, 4698, 79],\n",
       " [37, 18, 18, 146, 1047, 5, 6, 2],\n",
       " [239, 1554, 145, 3018, 151, 80, 1],\n",
       " [1, 1695, 327, 49, 81, 3674],\n",
       " [9, 54, 1, 26, 3, 676, 711, 730, 2620],\n",
       " [227, 3019, 1],\n",
       " [1434, 2621, 4699, 1555, 1696, 127, 121, 11],\n",
       " [5, 34, 49, 74, 587, 13, 94],\n",
       " [1, 32, 26, 3, 1154],\n",
       " [4700],\n",
       " [2040, 1048, 527, 64],\n",
       " [8, 568, 1697, 2028, 2297, 105, 34, 41, 1155, 856, 4],\n",
       " [145, 946, 27, 6756, 76, 6757, 320],\n",
       " [249, 11, 3020, 4701, 389],\n",
       " [6, 1, 4702, 3, 1698, 4703, 49, 479, 6758],\n",
       " [321, 45, 1, 111, 2041, 277],\n",
       " [51, 997, 1, 1556, 410, 1425, 66],\n",
       " [455, 1699, 194, 638, 748, 357],\n",
       " [161, 166, 3, 35, 174, 137, 1557, 149, 1850, 22, 585, 62, 31],\n",
       " [46, 59, 639, 6759, 10, 22, 1435, 6760, 2030, 432, 200, 1558, 55],\n",
       " [73, 1],\n",
       " [107, 6761, 28, 8, 142, 80, 388, 1851, 3675, 6, 3676, 6762, 1, 10],\n",
       " [679, 350, 3021, 3677, 621, 2622, 2],\n",
       " [3678, 1105, 122, 77, 1851],\n",
       " [210, 6763, 23],\n",
       " [637, 3022, 4704, 200, 162, 6764, 123, 1700, 1559, 480, 775],\n",
       " [46, 64],\n",
       " [199, 253, 148, 29, 48, 40, 24, 30, 2623],\n",
       " [32, 76, 1049],\n",
       " [111, 749, 528, 6765, 3679, 4705],\n",
       " [14, 2, 45],\n",
       " [94, 1436, 1331, 3023],\n",
       " [80, 78, 291, 6766, 56, 15, 2298, 279, 15, 3024, 1, 6, 780],\n",
       " [3680, 217, 46],\n",
       " [9, 1701, 1, 7],\n",
       " [48, 1560, 4, 29, 6, 351, 398, 3681, 456, 124, 9, 162, 115],\n",
       " [33, 1437, 3682, 444, 92, 947, 355, 658, 658, 658],\n",
       " [5, 15, 1, 1438, 86, 5, 15, 2, 4706, 205, 433, 3025, 2, 15, 5],\n",
       " [204, 1, 358, 228, 92, 454, 3026, 49, 6767, 113, 122],\n",
       " [6768, 71, 777, 6769, 6770, 6771],\n",
       " [434, 3, 2042, 4],\n",
       " [3027, 6772, 6773, 2599, 4707, 6774, 3028, 107, 124, 325, 37, 4708, 2299],\n",
       " [1, 18, 32, 1110, 68, 62, 161, 116],\n",
       " [948, 380, 3029, 3030, 6, 6775, 588, 998, 6, 3031, 37, 2, 100, 25, 38],\n",
       " [3, 728, 1, 4709],\n",
       " [175, 857, 1, 529],\n",
       " [130, 6776, 3682, 512, 156, 21, 205, 1332, 569],\n",
       " [582, 6777, 80, 30, 223, 72, 1232, 1233, 4710],\n",
       " [33, 265],\n",
       " [1439, 104, 487, 197, 83, 172, 120, 4711, 1156],\n",
       " [17, 3683, 143, 122, 106, 119, 324, 2297, 6778, 2300, 6779],\n",
       " [1561, 11, 1, 250],\n",
       " [1, 28, 513, 445, 1234, 12],\n",
       " [321, 149, 346, 14, 682, 97, 657, 121, 314, 6780],\n",
       " [6781, 157, 23, 949, 858, 214, 2301, 3032, 2624, 315, 726],\n",
       " [589, 4712, 3684, 212, 1702, 14, 8, 6782, 514, 4],\n",
       " [683, 7, 1, 3033],\n",
       " [3034, 1235, 297, 11, 1157, 2625, 11, 112, 1562, 4713],\n",
       " [50, 113, 30, 24, 168, 1550, 781, 20, 2302],\n",
       " [2303, 1151, 1563, 11, 552],\n",
       " [2304, 245, 3035, 6783, 2626, 265, 212],\n",
       " [1, 487, 227, 83],\n",
       " [66, 305, 1, 1236, 49, 1237, 10, 3036],\n",
       " [2, 17, 2, 640, 123],\n",
       " [191, 6784, 123, 3037, 1, 24, 88, 10],\n",
       " [2043, 1, 3685, 1111],\n",
       " [24, 1425, 999, 446, 2305, 6785, 553, 1238, 659, 76],\n",
       " [5, 76, 12],\n",
       " [250, 1, 346, 6786, 3686, 168],\n",
       " [1564, 78, 1565, 2],\n",
       " [13, 384, 2627, 15, 236, 3038, 1, 392, 328, 1703],\n",
       " [320, 1, 259, 6787, 590],\n",
       " [2306, 270, 1, 3687, 257, 126, 1158, 1050, 1852, 898, 467, 366, 3, 195, 316],\n",
       " [258, 1],\n",
       " [82, 3039, 161, 3, 1051, 1, 5, 6788],\n",
       " [12, 51, 24, 10, 3688, 1704, 133, 153, 1, 373, 260],\n",
       " [2307, 98, 3, 859, 750, 83, 141, 260, 1052, 23, 3001],\n",
       " [468, 469, 100, 142, 1853, 1158, 8, 115, 1705, 2, 10],\n",
       " [152, 4714, 2, 146, 3040],\n",
       " [399, 273, 860, 124, 43, 61, 15, 44, 1159, 6789, 27, 3689, 139, 3041, 684],\n",
       " [4, 81, 13, 1000],\n",
       " [157, 358, 6790, 12, 37, 26, 29, 3690, 342, 2],\n",
       " [174, 515, 7, 1, 188, 275, 44],\n",
       " [481, 201, 1566, 2044, 4715, 39, 2, 591],\n",
       " [1, 3, 13, 120, 43, 3, 13, 1, 43, 211, 70, 8, 13, 12],\n",
       " [529, 64],\n",
       " [2, 861, 2, 6791],\n",
       " [1, 731, 2026, 46],\n",
       " [336, 9, 1, 261, 166, 3, 8, 367, 3691],\n",
       " [3042, 1157, 1],\n",
       " [1854, 43, 137, 1854, 6, 899, 1706, 861, 1567],\n",
       " [1159, 256, 71, 6792],\n",
       " [1855, 1, 7, 5, 3012],\n",
       " [60, 1239, 10, 13, 83, 944, 898, 1],\n",
       " [1568, 1856, 60, 49, 587, 1],\n",
       " [127, 31, 4716, 346, 6793, 6794, 27, 488, 143],\n",
       " [1, 2628, 52],\n",
       " [782, 262, 3, 502, 2],\n",
       " [35, 1],\n",
       " [712, 1440, 1],\n",
       " [2, 224, 7, 424, 751, 900, 52, 1],\n",
       " [1112, 49, 1, 1707, 6795],\n",
       " [329, 23, 2308, 193, 6, 2045],\n",
       " [181, 275, 181, 6796, 901, 47, 23, 4717, 35],\n",
       " [570],\n",
       " [489, 281],\n",
       " [170, 47, 93, 19, 4, 434, 3, 516, 1549, 12],\n",
       " [1, 28, 8, 56],\n",
       " [46, 1, 32, 1857, 1160, 4718],\n",
       " [3043, 3043, 2],\n",
       " [158, 158, 2, 424, 571, 501, 363, 305, 435, 173, 274, 40, 530],\n",
       " [35, 417, 159, 425, 2309, 63, 1],\n",
       " [4719, 6797, 94, 1053, 616, 352, 208, 6798, 418, 1053],\n",
       " [2046, 4, 531],\n",
       " [215, 4720, 1],\n",
       " [9, 102, 676, 1],\n",
       " [113, 443, 117, 3044, 3692, 74, 862, 127, 121, 1569, 6799, 6800, 1001, 12],\n",
       " [322, 2, 6801, 407, 1858, 1570, 188],\n",
       " [24, 246, 1054, 408, 1, 408, 6802, 6803],\n",
       " [6, 5, 139, 5, 2],\n",
       " [86, 1, 815],\n",
       " [6804, 114, 105, 273],\n",
       " [86, 517, 16, 63, 622, 11, 190],\n",
       " [6805, 6806, 11, 1002, 136, 1113, 131, 43, 56, 6807, 1859, 1859, 388],\n",
       " [90, 641, 11, 1240],\n",
       " [181, 266, 2, 82, 323, 623, 5, 66],\n",
       " [46, 229, 624, 171, 2310, 5, 4721, 4],\n",
       " [2294, 1, 4, 4, 4722, 502, 2047, 6808, 2311],\n",
       " [134, 330, 1],\n",
       " [136, 1, 138, 1114, 541],\n",
       " [209, 4723, 15, 2],\n",
       " [243, 290, 1571, 165, 89, 642, 1323, 67, 1, 400, 379, 2033],\n",
       " [1, 17, 731, 1241, 1333, 336, 73, 1],\n",
       " [1, 554, 14, 99, 1, 713, 660, 503, 5, 98],\n",
       " [364, 70, 94, 6809, 72, 6810, 1708, 217, 1709, 3693, 12],\n",
       " [27, 398, 114, 6, 419, 3045, 6811, 6812, 6813, 2312, 243, 2629],\n",
       " [84, 2048, 44, 11],\n",
       " [151, 263, 1, 2049, 6814, 541, 24, 3694],\n",
       " [2, 643, 3695, 292, 863, 643, 3695, 56],\n",
       " [1, 181, 135],\n",
       " [1003, 616, 6815, 426, 27, 118, 4724, 151],\n",
       " [513, 1],\n",
       " [189, 9, 5, 685, 54, 1, 32, 75, 590],\n",
       " [50, 1, 1, 1],\n",
       " [518, 50, 1572, 2313, 15, 714, 605, 6816, 661, 230, 150, 192, 99, 519],\n",
       " [282, 231, 114, 427, 2630, 6817, 63, 3046, 950, 186],\n",
       " [1573, 26, 430, 258, 2, 89, 96, 51, 5, 527, 2314],\n",
       " [69, 132, 1, 45, 1242, 1441, 4725],\n",
       " [1331, 1, 1334, 5, 42],\n",
       " [435, 3047, 569, 298, 1, 1710],\n",
       " [134, 63, 105, 428, 1335, 1711, 6, 139, 542, 12, 73, 783, 85],\n",
       " [425, 8, 538, 6818, 15, 257, 322, 2],\n",
       " [662, 553, 1, 6819, 94, 1436, 6820],\n",
       " [5, 6, 1236, 102, 2050, 1, 116],\n",
       " [258, 11],\n",
       " [420, 2, 43, 6, 353, 26, 51, 4, 10],\n",
       " [490, 11],\n",
       " [271],\n",
       " [1442, 2],\n",
       " [281, 864, 660, 784, 124, 1712, 394, 2631, 308, 41, 35],\n",
       " [374, 470, 10, 7, 3, 6821, 785, 6822, 1574, 56, 4726, 7, 1243, 6823],\n",
       " [65, 12, 6824],\n",
       " [379, 19, 3696, 2],\n",
       " [4727, 6, 819, 77, 46],\n",
       " [1, 107, 14, 267, 272],\n",
       " [9, 3697, 9, 265, 584],\n",
       " [86, 44, 1],\n",
       " [20, 4, 170, 12],\n",
       " [6825, 6826, 1713, 47, 14, 1, 108, 3698],\n",
       " [1],\n",
       " [3, 1, 14, 6, 119, 1575],\n",
       " [222, 206, 2315, 83, 3651, 45, 1545, 606, 2051, 11],\n",
       " [213, 6827],\n",
       " [4728, 6828, 2316, 1004, 6829, 1851, 331, 38, 6830, 820, 23],\n",
       " [2632, 15, 4729, 3048, 1115, 3699, 260, 752, 2052, 352],\n",
       " [622, 497, 426, 2633, 172, 108, 10, 101, 357, 2317, 1, 46],\n",
       " [59, 1, 82, 41],\n",
       " [1055, 3700, 6831, 1, 1055, 3, 16, 1107, 19],\n",
       " [1, 6832],\n",
       " [3701, 96, 51, 1557, 27, 109, 2053, 1, 175, 817],\n",
       " [6833, 6834],\n",
       " [1, 6, 786, 4730, 185],\n",
       " [310, 4, 8, 132, 4731],\n",
       " [451, 1, 365, 271],\n",
       " [1005, 16, 38, 288, 4732, 256, 2, 504],\n",
       " [1, 147, 54, 7, 20, 663, 4733, 3702, 2634, 5, 50, 95, 14, 10],\n",
       " [73, 1, 487, 4734],\n",
       " [4735, 62, 121, 63, 171, 1, 1860, 203, 63, 171],\n",
       " [283, 3703, 284, 70, 179, 34, 52, 352, 902, 55, 2635, 118, 2],\n",
       " [1443, 395, 3049, 4736, 1442, 2309, 3704, 1861],\n",
       " [902, 61, 12, 1444],\n",
       " [420, 11, 60, 2595, 516, 1445, 59, 686, 2054],\n",
       " [1116, 18, 951, 3, 4, 7, 5, 1858],\n",
       " [6835, 4737, 6836, 6837, 6838, 2, 2, 2, 1446, 3050, 4738, 394, 625],\n",
       " [17, 2055, 2055],\n",
       " [995, 1],\n",
       " [21, 1161, 1566, 11, 1244],\n",
       " [491, 251, 1, 2056, 6839],\n",
       " [41, 687, 66, 10, 1245, 48, 3, 1, 4],\n",
       " [1, 1, 505, 1006, 359, 254, 6840, 104],\n",
       " [168, 770],\n",
       " [778, 753, 6841, 110, 255, 4739, 492, 110],\n",
       " [1, 381, 1862, 504, 420, 14, 2057, 2058, 38, 2636, 732],\n",
       " [191, 113, 21, 22, 160, 2, 176],\n",
       " [6842, 1446, 4740, 3, 1, 322, 2637, 182, 4740, 1],\n",
       " [33, 572, 664, 1],\n",
       " [288, 4],\n",
       " [2, 1056],\n",
       " [6843, 169, 3, 1246],\n",
       " [1162, 6844, 6845, 1576, 243, 540, 23, 528],\n",
       " [195, 203, 2318, 2319, 715, 1],\n",
       " [48, 73, 1, 13, 987, 2638],\n",
       " [3033, 662, 2, 3705, 12, 145, 1577, 679, 350, 160],\n",
       " [6, 310, 784, 4, 218, 4741, 52, 218, 1336, 446, 4742, 199, 375],\n",
       " [952, 41, 3051, 332, 240, 356, 4743, 1247],\n",
       " [9, 90, 351, 63, 103, 821, 822, 12, 26, 20, 76],\n",
       " [247, 4744, 6846, 257, 6847, 3052, 1057, 2320, 1],\n",
       " [90, 6848, 10, 3053, 6849, 63, 6850, 659, 1714, 100, 6851, 3681],\n",
       " [4745, 2609, 6852, 6853, 940, 236, 11, 8, 26],\n",
       " [343, 80, 4, 1007, 41, 29, 104],\n",
       " [14, 823],\n",
       " [47, 305, 11],\n",
       " [12, 107, 163, 29, 1578, 1, 17, 1447, 1248, 3054, 1448],\n",
       " [26, 20, 76, 3055, 1046, 1715],\n",
       " [903, 2639, 499, 98, 33, 514],\n",
       " [708, 9, 1337, 2640, 1, 7, 5, 35, 18, 8, 1863, 621],\n",
       " [134, 330, 331, 65, 45, 453, 506, 1104, 404],\n",
       " [6854, 79, 530, 507],\n",
       " [2, 4746, 644, 35, 67, 6855, 4747, 1449, 7, 2, 9, 865],\n",
       " [57, 1, 70, 8, 94, 6856, 84, 22, 98, 88, 6, 117, 1569, 168],\n",
       " [137, 607, 400, 1249],\n",
       " [296, 1],\n",
       " [154, 2, 506, 404, 2, 645],\n",
       " [2059, 942, 1450, 1449, 217, 3706, 194, 754],\n",
       " [20, 30],\n",
       " [302, 205, 1],\n",
       " [6857, 1048, 3, 22, 2641, 684, 11, 2641, 221, 40, 6858, 3056],\n",
       " [5, 13, 1, 272, 14, 1250, 1054, 482],\n",
       " [74, 1338, 3057, 277, 6859, 3058, 6860, 24],\n",
       " [626, 64],\n",
       " [107, 627, 24, 95, 126, 1690, 285, 1],\n",
       " [1451, 6861, 1008, 54, 30],\n",
       " [442, 1163, 3059, 44, 7, 60, 11, 372, 10, 93],\n",
       " [12, 73, 1],\n",
       " [311, 71, 777, 2060, 238, 6862, 6863, 1864, 2642, 2643],\n",
       " [157, 22, 6864, 1579, 2634, 3, 226, 1580, 128, 27],\n",
       " [1149, 43, 2, 81],\n",
       " [6865, 6866, 143, 4748, 3060, 6867, 2061, 56, 6868, 21, 3061, 4749],\n",
       " [413, 1],\n",
       " [28, 1, 436, 65],\n",
       " [130, 104, 24, 28, 17, 45, 32, 445, 17, 143],\n",
       " [262, 3, 25, 1],\n",
       " [866, 491, 2062, 6869],\n",
       " [133, 8, 259, 23, 146, 92, 6870],\n",
       " [392, 3062, 1581, 455, 74, 1582],\n",
       " [101, 270, 248, 310, 3021, 97, 3707, 33, 268, 754, 6871, 88, 44, 1],\n",
       " [13, 6872, 6873, 66, 6874, 4750, 1058, 228, 54, 10, 36, 200, 14, 37],\n",
       " [2644, 1, 7, 6875, 8, 3708, 466],\n",
       " [6876, 1],\n",
       " [39, 1],\n",
       " [13, 44, 5, 1006, 1339, 4751, 3709, 66, 1],\n",
       " [24, 10, 118, 170, 1, 387, 27, 14, 519, 688, 10],\n",
       " [26, 278, 315, 53, 6, 2],\n",
       " [2, 162, 2, 36],\n",
       " [153, 204, 6877, 355, 119, 105],\n",
       " [485, 6878, 658, 72, 4, 3710, 15, 50, 3063, 1716],\n",
       " [90, 75, 307, 183, 1427, 84, 678, 293, 156],\n",
       " [4752, 159, 38, 6879, 1452, 813, 82],\n",
       " [1717, 1340, 236, 4, 322],\n",
       " [19, 1865, 2063, 2],\n",
       " [904, 103, 299, 6880],\n",
       " [33, 1, 32, 253, 13, 337, 7, 3, 204],\n",
       " [40, 171, 1453, 2289, 145, 67, 2645, 144, 1],\n",
       " [1164, 140, 63, 1866, 7, 137, 12],\n",
       " [3064, 2, 46],\n",
       " [12, 6881, 54, 437],\n",
       " [251, 3065, 4753, 30],\n",
       " [267, 31, 83, 90, 822, 447],\n",
       " [134, 1165, 2042, 2040, 92, 368, 1, 551, 6882],\n",
       " [155, 1, 238],\n",
       " [136, 573, 43, 231, 5, 9, 23],\n",
       " [2, 6, 43, 104, 10, 638, 6883, 104, 6884, 2321, 82, 3711],\n",
       " [66, 212, 17, 310, 4],\n",
       " [704, 40, 319, 1059, 3, 303, 4754, 70, 64, 528],\n",
       " [6885, 6886, 665, 1],\n",
       " [6887,\n",
       "  2646,\n",
       "  2322,\n",
       "  297,\n",
       "  141,\n",
       "  342,\n",
       "  542,\n",
       "  452,\n",
       "  177,\n",
       "  3066,\n",
       "  279,\n",
       "  160,\n",
       "  247,\n",
       "  408,\n",
       "  69,\n",
       "  1],\n",
       " [787, 9, 2323, 4, 140],\n",
       " [145, 37, 1161, 2064, 2647],\n",
       " [6888, 1432, 3019, 1, 363, 628, 2065, 6889, 4755],\n",
       " [2044, 6890, 240, 71, 350],\n",
       " [114, 3, 1166, 471, 6891],\n",
       " [2, 5, 6892],\n",
       " [592, 3, 4756, 1251, 6893, 2, 2286],\n",
       " [227, 1, 48, 3067],\n",
       " [1718, 45, 715, 2],\n",
       " [6894, 2312, 20, 61, 3712, 82],\n",
       " [6895, 625, 4],\n",
       " [1],\n",
       " [291, 666, 2, 46],\n",
       " [11],\n",
       " [15, 9, 1],\n",
       " [6, 367, 44, 2, 6896, 87, 45, 2066, 6897],\n",
       " [4757, 138, 5, 60, 11, 1583, 733, 4758, 333],\n",
       " [569, 1584, 4759, 569, 1719, 4760, 6898, 689, 4761, 608, 706, 1167],\n",
       " [109, 6899, 16, 6900, 176],\n",
       " [46, 5, 1252, 47, 21, 6901, 55, 367, 1, 58, 2324],\n",
       " [9, 6902, 66],\n",
       " [1454, 471, 6903, 4762, 690, 3068, 492],\n",
       " [32, 126, 1455, 2, 176],\n",
       " [1, 407, 1858, 1570, 188, 135, 953, 6, 10, 2325, 18, 59],\n",
       " [9, 6, 6904, 316, 1, 87, 905, 69, 6905, 2648, 8, 177, 286],\n",
       " [755, 40, 4763, 32, 4764, 1, 2067],\n",
       " [2649, 2, 753, 295, 18, 110, 788, 2649, 2649, 2, 1253, 2649],\n",
       " [457, 23, 322, 954],\n",
       " [366, 6906, 15, 6907, 566, 6, 1, 2068, 953, 1248],\n",
       " [4765, 53, 1, 622, 28, 2326, 824, 55, 824, 7],\n",
       " [574,\n",
       "  2327,\n",
       "  80,\n",
       "  4766,\n",
       "  867,\n",
       "  206,\n",
       "  1117,\n",
       "  37,\n",
       "  3673,\n",
       "  1,\n",
       "  7,\n",
       "  3713,\n",
       "  208,\n",
       "  6908,\n",
       "  149,\n",
       "  2069,\n",
       "  77],\n",
       " [867, 746, 5, 161, 34, 2, 7, 97, 401, 66, 6909],\n",
       " [51, 31, 278, 13, 27, 13, 634, 53, 1, 8, 1444],\n",
       " [96, 10, 1009, 10, 1, 10, 56, 10, 5, 10, 213],\n",
       " [6910, 4767, 3, 897, 1339, 1585, 44, 11, 825, 17, 6911, 1055, 4768, 543],\n",
       " [2],\n",
       " [1424, 906, 11, 27, 11, 12],\n",
       " [1, 489, 8],\n",
       " [1168, 4, 7, 10, 458, 3, 907, 17, 1254, 907, 214, 6912, 35, 1169, 97],\n",
       " [10, 1255, 201, 2037, 6913, 88, 7, 1],\n",
       " [2, 256, 646, 91, 1, 1170, 1720, 356, 1060, 2650, 6914, 4],\n",
       " [1],\n",
       " [2, 285, 2, 2, 14, 106, 2, 2, 285, 2],\n",
       " [3714, 6915, 24, 3, 44, 149, 207, 2070, 1433, 539, 199, 168, 532, 732, 1, 7],\n",
       " [152, 456, 520, 71, 6916, 6917, 119],\n",
       " [1456, 3, 54, 1, 635],\n",
       " [593, 34, 1171, 2071, 3715, 8, 1860, 376, 59, 6918, 136, 223, 159, 6919],\n",
       " [1, 6, 6920, 42, 193, 1457, 36, 530, 4769],\n",
       " [16, 555, 353, 1],\n",
       " [450, 1],\n",
       " [228, 13, 36, 14, 3716, 11, 6921, 10, 629, 2072, 309, 3717],\n",
       " [2651, 1, 3038, 6922, 6923],\n",
       " [2, 159],\n",
       " [1545, 130, 3069, 31, 30, 6, 10, 419],\n",
       " [170, 161, 189, 130, 104, 712, 1, 220],\n",
       " [4770, 203, 656, 4771, 130, 2652, 6924, 82, 174],\n",
       " [393, 60, 25, 6925, 149, 2328, 5, 6926],\n",
       " [186, 4, 574],\n",
       " [91, 1, 3, 667, 317, 1, 6927, 6928],\n",
       " [61, 12, 2653, 1002, 12, 3718, 4772, 373, 405, 396, 3070, 3718, 12],\n",
       " [3071, 7, 28, 6929, 1, 405, 4711, 266, 119, 38, 35],\n",
       " [556, 13, 283, 544, 7, 1, 7, 1051, 7, 443, 1172],\n",
       " [6930,\n",
       "  246,\n",
       "  128,\n",
       "  208,\n",
       "  1173,\n",
       "  3719,\n",
       "  208,\n",
       "  6931,\n",
       "  4773,\n",
       "  161,\n",
       "  6932,\n",
       "  6933,\n",
       "  6934,\n",
       "  4774],\n",
       " [4, 7, 40, 569, 2654, 992, 1564, 40, 37, 3720, 236, 257],\n",
       " [131, 267, 32, 268, 4, 711, 4, 531, 4775, 216],\n",
       " [756, 1, 129, 4776],\n",
       " [41, 45, 447, 83, 946, 74, 1341, 236, 868],\n",
       " [1, 1721],\n",
       " [1, 6935, 1848, 9, 2291, 9, 55, 1],\n",
       " [150, 117, 1446, 21, 224, 3, 73, 1],\n",
       " [3721, 6, 2655, 1, 506],\n",
       " [1168,\n",
       "  347,\n",
       "  35,\n",
       "  9,\n",
       "  49,\n",
       "  869,\n",
       "  4777,\n",
       "  587,\n",
       "  162,\n",
       "  2329,\n",
       "  2073,\n",
       "  4778,\n",
       "  1118,\n",
       "  232,\n",
       "  307,\n",
       "  2],\n",
       " [6936, 23, 2656],\n",
       " [3722, 1010, 1],\n",
       " [2, 2, 442, 6937, 14],\n",
       " [826, 4779, 2074, 3723, 678, 1342, 1149, 668],\n",
       " [14, 42, 18, 1722, 14, 43, 1],\n",
       " [139, 188, 307, 4780, 285, 433, 9, 433, 4, 109],\n",
       " [315, 137, 6938],\n",
       " [1, 22, 3072, 198, 3073, 691],\n",
       " [4781, 3074, 1, 12, 13, 57, 530, 31, 6939, 12],\n",
       " [92, 368, 4782, 4783, 38, 43, 230, 1723, 3724, 955],\n",
       " [500, 444, 1, 444, 259, 429, 1, 259, 429],\n",
       " [5, 6940, 11, 46, 3075, 11],\n",
       " [43, 5, 309, 1005, 894, 74, 757, 1, 956, 1055],\n",
       " [4784, 27, 334],\n",
       " [6941, 11, 90, 47, 29],\n",
       " [4785, 47, 1343, 118, 274, 251, 6942, 3076, 1],\n",
       " [3725,\n",
       "  186,\n",
       "  6943,\n",
       "  856,\n",
       "  169,\n",
       "  333,\n",
       "  2075,\n",
       "  169,\n",
       "  2076,\n",
       "  22,\n",
       "  1448,\n",
       "  333,\n",
       "  2330,\n",
       "  773,\n",
       "  3726],\n",
       " [3060, 2, 6, 16, 170],\n",
       " [6, 221, 1, 371, 50, 1, 508],\n",
       " [250, 1, 779, 565, 123, 171, 1586, 734, 748, 431, 944],\n",
       " [2077, 40, 14, 995, 1],\n",
       " [13, 870, 3727, 95, 1, 355],\n",
       " [29, 71],\n",
       " [214, 1235, 11, 69, 6944, 43, 528],\n",
       " [16, 31, 188, 135, 19, 152, 104, 2054, 6945, 152, 2054, 990, 6946, 528, 1],\n",
       " [2657, 480, 15, 2658, 83, 1174, 692, 871, 11, 1867, 1550, 15, 6947],\n",
       " [4786, 1587, 1724, 4787, 4, 425, 434, 253, 552, 3077],\n",
       " [40, 28, 280, 519, 1, 861, 58, 1255, 10],\n",
       " [64],\n",
       " [6948, 1119, 127, 121, 1453, 1868, 2659, 1, 7],\n",
       " [6949, 30],\n",
       " [138, 112, 2, 1705],\n",
       " [1, 24, 6950, 2],\n",
       " [1, 42, 22, 669, 1],\n",
       " [34, 1344, 23, 1867, 480, 321, 249, 59, 218, 1449, 6951],\n",
       " [690, 44, 11],\n",
       " [2078, 1, 7, 529],\n",
       " [3728, 48, 6952, 1, 6953],\n",
       " [1, 4788, 3729],\n",
       " [2, 70, 237, 5, 2, 2],\n",
       " [13, 941, 143],\n",
       " [113, 2027, 4789, 2660, 96, 11, 4790, 1869, 2079, 6954, 42, 4791, 4792],\n",
       " [533, 1, 182, 2661],\n",
       " [6955, 36, 1, 872, 908, 16, 31, 377],\n",
       " [284, 5, 6, 6956, 604, 4, 83, 115],\n",
       " [37, 18, 735, 2662, 105, 6957, 107, 18, 574, 6958, 6959, 716, 1, 448, 10],\n",
       " [295, 6960, 1458, 1047, 683, 7, 1, 6961, 248],\n",
       " [11, 87, 713, 6962, 13, 160, 4793, 352],\n",
       " [9, 6963, 570, 897, 3, 127, 105, 483, 656, 374],\n",
       " [4794, 374, 120, 3, 363, 1011, 5, 6964, 1, 665, 1725, 618, 270],\n",
       " [1459, 143, 56],\n",
       " [4795, 1012, 19, 2080, 1, 21, 582, 1870, 15, 3730],\n",
       " [9, 1, 32],\n",
       " [70, 83, 4796, 208, 74, 3731, 3078],\n",
       " [27, 191, 91, 344, 3079, 21, 169, 4797, 6965, 717, 1726, 101],\n",
       " [1, 8],\n",
       " [6966, 637, 160, 319, 29, 2663, 11, 6967, 320],\n",
       " [827, 7, 6968, 260, 1460, 3732, 21, 2, 718, 39, 446, 10, 4798],\n",
       " [8, 29, 4, 1461, 3, 402, 127, 1727, 313],\n",
       " [12, 391, 26, 1, 7, 13],\n",
       " [1, 243, 525, 54, 3702, 7, 104, 953, 14, 5, 953, 227, 24],\n",
       " [34, 98, 3080, 1871, 48, 2331, 50, 479, 545, 869, 1175],\n",
       " [113, 153, 4799, 234, 1251, 11, 152, 210, 409, 3, 3733, 53],\n",
       " [82, 174, 396, 6969, 2664, 3734, 3735, 167],\n",
       " [1, 101, 376, 8, 53],\n",
       " [1345, 1],\n",
       " [2665, 20, 1, 8, 556, 13, 28, 734, 4800, 56],\n",
       " [3, 1462, 1],\n",
       " [1728, 1, 42, 180, 3684],\n",
       " [202, 1],\n",
       " [1, 14, 3081],\n",
       " [2, 6, 789, 56, 3, 909, 45],\n",
       " [1, 12],\n",
       " [89, 96, 18, 22, 60, 18, 96, 3, 156],\n",
       " [188, 135, 28, 162, 236, 502, 3736, 272, 187, 14, 79, 157],\n",
       " [245, 47, 4801, 30, 260, 4802, 6970, 1872, 663],\n",
       " [1, 67, 3082, 8, 356],\n",
       " [1729, 55, 4, 431],\n",
       " [108, 6971, 2081, 2],\n",
       " [384, 108, 3083, 163, 909, 2, 469],\n",
       " [214, 3084, 10, 758, 534, 1, 759],\n",
       " [20, 86, 1, 13, 4803, 636, 112, 123, 910, 2642, 6972],\n",
       " [41, 49, 421, 1, 51, 1120],\n",
       " [110, 154, 186, 400, 125, 3737, 255, 140],\n",
       " [323, 2332, 1, 7, 69, 688, 229, 1873, 147, 277],\n",
       " [98, 25, 239, 19, 175, 2],\n",
       " [1707, 4, 1730],\n",
       " [1256,\n",
       "  74,\n",
       "  670,\n",
       "  121,\n",
       "  350,\n",
       "  6973,\n",
       "  729,\n",
       "  1321,\n",
       "  6974,\n",
       "  6975,\n",
       "  1463,\n",
       "  6976,\n",
       "  275,\n",
       "  409,\n",
       "  6977],\n",
       " [787,\n",
       "  9,\n",
       "  44,\n",
       "  1,\n",
       "  125,\n",
       "  623,\n",
       "  241,\n",
       "  374,\n",
       "  1874,\n",
       "  2026,\n",
       "  873,\n",
       "  1,\n",
       "  303,\n",
       "  21,\n",
       "  151,\n",
       "  314,\n",
       "  3085],\n",
       " [3738, 2666, 1004, 355, 27, 1],\n",
       " [736, 3739, 6978, 751, 34, 141, 1875, 1876, 6979, 2667, 6980, 6981, 213],\n",
       " [401, 71, 1346, 615, 594, 15, 6982, 1347, 2298, 1121],\n",
       " [1877, 1877, 1877, 13, 459, 521, 6, 1005, 1711, 116, 44, 7, 65],\n",
       " [26, 50, 3086, 50, 95, 2333, 24, 630, 556, 6983, 14, 552, 1, 147, 157, 528],\n",
       " [107, 1, 249, 37, 444],\n",
       " [59, 3087, 130, 6984, 80, 1588, 77],\n",
       " [1061, 2334, 4],\n",
       " [647, 1, 6985, 2668],\n",
       " [546, 4804, 1, 36, 3740, 151, 3740],\n",
       " [681, 284, 50, 1459, 143, 31, 48, 32, 1878, 1879, 853, 61, 2654],\n",
       " [414, 42, 9, 1, 2335, 223],\n",
       " [189, 726, 1],\n",
       " [1, 378],\n",
       " [6, 62, 360, 98, 3, 1],\n",
       " [254, 71],\n",
       " [1, 41, 134, 6, 6986, 555, 92, 1257, 1589, 193, 3741, 468, 6987],\n",
       " [1, 112, 343],\n",
       " [95, 2, 155, 175, 380, 85, 390, 100],\n",
       " [1006, 502, 76, 7, 1731, 98, 177],\n",
       " [3088, 3089, 1, 3742, 467],\n",
       " [25, 1, 27, 13],\n",
       " [6988, 2336, 2337, 416, 1165, 69, 1880, 212, 16, 1732, 1],\n",
       " [50, 44, 11, 66],\n",
       " [4805, 3090, 31, 1],\n",
       " [294, 5, 37, 3743, 101, 2],\n",
       " [137, 6, 238, 293, 6989, 2],\n",
       " [4, 7, 5],\n",
       " [509, 1],\n",
       " [567, 194, 13, 194, 113, 1435],\n",
       " [110, 38, 1, 7, 334],\n",
       " [245, 15, 3091, 1176, 15, 162, 24, 147, 1, 1733, 1051],\n",
       " [6, 25, 1, 567],\n",
       " [1464, 2],\n",
       " [1327, 1, 9, 2338],\n",
       " [1, 458],\n",
       " [6, 265, 6, 4806],\n",
       " [23, 1465],\n",
       " [90, 2621, 911, 3092, 20, 156, 3093, 4807, 3744, 1590, 1058, 2082, 1734],\n",
       " [85, 68, 4808, 114, 4808],\n",
       " [19, 299, 289, 60, 2],\n",
       " [368, 34, 2, 103, 63, 105, 63],\n",
       " [9, 7, 498, 1466],\n",
       " [760, 295, 2083, 641, 604, 1003, 395, 2339, 3745, 122],\n",
       " [308, 3075, 557, 1467, 595, 84, 45, 472, 1056, 7, 1],\n",
       " [48, 6990, 6991, 146, 1177, 380, 6992, 121, 2340, 6993, 1591, 36, 1881, 1],\n",
       " [54, 20, 30, 1429, 332, 189, 145, 1258, 20, 1259],\n",
       " [114, 37, 184],\n",
       " [242, 596, 1, 6994, 343, 12, 1592],\n",
       " [912, 790, 135, 3094, 4, 3746, 547, 1107, 3747],\n",
       " [16, 85, 8, 205, 1],\n",
       " [2, 6995, 5, 3748, 4809, 146, 2669, 73, 460, 2, 6996, 7, 5],\n",
       " [16, 129, 1002, 1735, 1178, 6997, 2084, 3749, 6998, 1179, 498],\n",
       " [233, 7, 1, 170, 12],\n",
       " [6, 179, 1, 490, 874],\n",
       " [2, 96, 27, 221, 333, 2, 98, 6999, 7000, 166, 7001],\n",
       " [1, 22, 134, 2085, 4810, 22, 1, 134],\n",
       " [83, 1046, 16, 538, 31, 3, 84, 72, 7002, 875, 4, 2670],\n",
       " [4, 87],\n",
       " [12, 1, 133, 384, 3, 432, 443, 7003, 7004, 2, 2341, 606],\n",
       " [152, 165, 1587, 4811, 86, 15, 162, 24, 1056, 54, 1, 159, 36, 1, 14],\n",
       " [90, 491, 1158, 83, 1468, 2342, 100, 445, 4, 4812, 19, 310, 1469],\n",
       " [2, 771, 20, 2, 2086, 215, 50, 122, 7005],\n",
       " [414, 28, 3053, 7006, 249, 18, 89, 1013, 2343],\n",
       " [3750, 785, 100, 213],\n",
       " [59, 1, 1004, 355, 1055, 118],\n",
       " [82, 557, 1, 1, 913, 465, 207],\n",
       " [665, 552, 465, 1, 184, 52, 2310, 4813, 465, 1, 184, 52],\n",
       " [671, 597, 2, 7007],\n",
       " [138, 7008, 371, 91, 344, 2],\n",
       " [4814, 198, 1736, 1043, 4807, 45, 282, 2344, 71, 350, 215, 753, 705],\n",
       " [145, 415, 156, 157],\n",
       " [7009, 1],\n",
       " [2345, 244, 16, 38, 571, 376, 994, 452, 876, 1348, 3095, 7010, 34, 158],\n",
       " [1],\n",
       " [210, 4815, 78, 1003, 410, 395, 3751, 135],\n",
       " [159, 376, 211, 3752, 1],\n",
       " [7011, 59, 877, 43, 473, 5, 10, 59, 877, 80, 49, 598, 7, 2, 7012, 12],\n",
       " [95, 54, 1163, 351, 9, 1470, 1],\n",
       " [1, 791],\n",
       " [4816, 1, 18, 34, 180, 443, 1172],\n",
       " [1, 914, 878, 1, 2333],\n",
       " [114, 7013, 3753, 2087, 3753],\n",
       " [1456, 66, 2, 5, 9, 10],\n",
       " [84, 6, 1062, 338, 217, 1449, 2671, 159, 215, 1716, 7014, 2088, 2672],\n",
       " [58, 3754, 1882, 7, 192],\n",
       " [557, 8, 876, 1737, 16, 31, 1063, 74, 278],\n",
       " [3755, 294, 7015],\n",
       " [153, 16, 144, 7016, 1593, 122, 522, 3756, 241, 11, 558, 2673],\n",
       " [115, 8, 3757, 38, 528],\n",
       " [21, 267, 37, 98, 25, 1],\n",
       " [371, 1, 24, 86, 5, 375, 500, 24, 7017, 609, 500],\n",
       " [1, 133, 734],\n",
       " [1349, 1349, 225, 915],\n",
       " [610,\n",
       "  1350,\n",
       "  863,\n",
       "  1260,\n",
       "  3096,\n",
       "  73,\n",
       "  3097,\n",
       "  679,\n",
       "  350,\n",
       "  1,\n",
       "  1883,\n",
       "  90,\n",
       "  7018,\n",
       "  92,\n",
       "  501,\n",
       "  1109,\n",
       "  318,\n",
       "  559,\n",
       "  392],\n",
       " [140, 1, 7019],\n",
       " [321, 232, 16, 361, 93, 706, 876, 39, 7020, 7021],\n",
       " [7022, 2089, 29, 1587],\n",
       " [7023, 28, 1351, 4817, 1],\n",
       " [1, 199],\n",
       " [369, 648, 142, 25, 1],\n",
       " [1, 42, 32, 648, 49],\n",
       " [5, 166, 3, 241, 1],\n",
       " [30],\n",
       " [1],\n",
       " [558, 45, 3028, 7024, 7025, 7026, 335, 90, 2316, 244, 4818, 1738, 2090],\n",
       " [375, 4819],\n",
       " [331, 19, 133, 8, 2647, 136, 2, 133, 8, 4820],\n",
       " [37, 6, 31, 1, 792, 4821],\n",
       " [16, 176, 161, 7027, 68, 2, 1064],\n",
       " [4, 137, 104, 6, 465],\n",
       " [1, 32, 14, 266],\n",
       " [474, 244, 999, 36, 3098, 637, 446, 32, 548, 2091, 7028],\n",
       " [100, 2092, 3099, 915, 28, 2346, 693, 693, 247, 7029, 1261, 438, 29],\n",
       " [1262, 72, 332, 405, 3758, 272, 25, 1, 4822, 5, 1884],\n",
       " [319, 2674, 86, 1, 7, 300, 102],\n",
       " [429, 13, 202, 574, 851, 272, 21, 22, 1122, 607, 109, 192, 3759],\n",
       " [1, 6, 647, 3100],\n",
       " [4823, 13, 30, 131, 30, 3],\n",
       " [73, 1, 7030, 129, 277, 18, 24],\n",
       " [4824, 9, 1352, 28, 513, 546, 3760, 8, 559],\n",
       " [4825, 1],\n",
       " [1263, 1263, 1],\n",
       " [44, 11, 3101],\n",
       " [1, 181, 1739, 188, 188, 501],\n",
       " [7031, 169, 1885, 172, 861, 308, 88],\n",
       " [2, 792],\n",
       " [222, 2675, 5, 995, 29, 231, 2],\n",
       " [246, 47, 51, 165, 21, 3761, 1, 92, 1353, 367, 7032],\n",
       " [2676, 3102, 1, 216],\n",
       " [1, 822, 557, 212, 1740],\n",
       " [23, 7, 5, 92, 828, 4826, 3687, 85, 342, 97, 7033],\n",
       " [5, 4827, 4828, 48, 92, 4],\n",
       " [2, 398, 22, 134, 351, 2031, 134, 620, 38],\n",
       " [1264, 548, 1264, 2, 548],\n",
       " [556,\n",
       "  1243,\n",
       "  7034,\n",
       "  4,\n",
       "  3762,\n",
       "  988,\n",
       "  3,\n",
       "  2052,\n",
       "  2347,\n",
       "  734,\n",
       "  2347,\n",
       "  2052,\n",
       "  2052,\n",
       "  2052,\n",
       "  1886,\n",
       "  4829,\n",
       "  3762,\n",
       "  3762],\n",
       " [866, 1],\n",
       " [27, 195, 72, 5, 47, 1, 1471, 598],\n",
       " [1065, 1065, 1065, 1065, 1065],\n",
       " [229, 82, 198, 378, 52, 4, 24, 209, 9, 957, 438, 3, 7035],\n",
       " [2, 92, 424, 83, 10, 3, 7036, 7037, 1354],\n",
       " [12, 113, 20, 1],\n",
       " [1, 2348, 694],\n",
       " [7038, 1, 7, 5, 5, 737, 356, 339, 8, 108, 829, 569, 116],\n",
       " [30],\n",
       " [339, 1180, 15, 236, 4, 3763],\n",
       " [84, 666, 30, 1741],\n",
       " [912, 1333, 830, 7039, 3, 854, 12],\n",
       " [283, 7040, 1, 3764, 5],\n",
       " [1, 162, 2349, 822, 49, 1066, 786],\n",
       " [2093, 1887, 363, 80, 1, 4830],\n",
       " [793, 180, 3, 518, 237, 29, 4831, 1472, 30, 180, 223],\n",
       " [70, 159, 2677, 217, 2350, 217, 145, 7041],\n",
       " [3765, 192, 1004, 12, 411, 4832],\n",
       " [204, 1857, 1],\n",
       " [57, 45, 1888],\n",
       " [6, 1889, 89, 1, 589, 1123, 119, 5],\n",
       " [1, 60, 10, 997, 10],\n",
       " [3766, 126, 995, 114, 7042, 2323],\n",
       " [29, 1124, 2678, 16, 1, 68, 7043, 67, 3103],\n",
       " [21, 1108, 66, 11, 3],\n",
       " [28, 43, 1],\n",
       " [33, 1, 17, 1, 24, 17, 5, 831, 7, 1, 162, 158, 1, 241, 1],\n",
       " [1, 12],\n",
       " [4824, 254, 1473, 361, 307, 7044, 281],\n",
       " [21, 14, 9, 916, 227, 6, 147, 76, 7],\n",
       " [7045, 794, 4833, 493, 795, 112, 4],\n",
       " [2679, 212, 1, 120],\n",
       " [29, 19, 643, 2094, 2],\n",
       " [81, 28, 4, 57],\n",
       " [7046, 1067, 1, 819, 2095, 149, 7047, 575, 754],\n",
       " [2351, 4, 3767, 7048, 22, 10, 873],\n",
       " [1014, 422, 1068],\n",
       " [77],\n",
       " [211, 1594, 1],\n",
       " [4834, 382, 7049, 3768, 4835, 7050, 1069, 3077, 380, 1595, 95, 1],\n",
       " [43, 56, 30, 82, 185, 139, 27, 142, 19, 6, 59, 3, 27, 351],\n",
       " [130, 493, 776, 761, 599, 275, 1070, 1181, 1596],\n",
       " [32, 154, 7051, 879, 2994, 1071, 4, 32],\n",
       " [17, 25, 1, 80, 221],\n",
       " [1182, 1160, 77],\n",
       " [604, 247, 1742, 475, 6, 3065, 748, 1, 92, 435, 4836, 2096, 7052],\n",
       " [16, 2097, 1743, 2680, 7, 1, 9],\n",
       " [2, 2352, 43, 85, 207],\n",
       " [1, 1183, 72, 7],\n",
       " [192, 274, 7053, 2098],\n",
       " [411, 1744, 636, 37, 869, 7054, 27],\n",
       " [242, 13, 67, 218, 454, 62, 1342, 2681, 514, 141, 186],\n",
       " [695, 164, 388, 1576, 494, 164, 1890, 1, 2682],\n",
       " [445, 8, 399, 203, 2, 1, 10, 116],\n",
       " [987, 3104, 1009, 73, 1, 13, 987, 2638],\n",
       " [88, 54, 64, 159, 69, 8, 3032, 940, 1429, 40, 20, 234],\n",
       " [1, 7055, 211, 97, 535],\n",
       " [189, 7056, 77, 2353, 59, 235, 481, 90, 26, 7057],\n",
       " [358, 2, 333, 176, 7058, 358, 333, 7059, 7060, 2],\n",
       " [14, 346, 1597, 436, 4, 1],\n",
       " [24, 178, 439, 3105, 178, 1474, 1598, 232, 84],\n",
       " [226, 1, 1694, 7061],\n",
       " [1, 880, 1745, 3769, 122],\n",
       " [15, 1, 1891, 8, 385, 1599, 5, 648, 107],\n",
       " [506, 1184, 19, 209, 317, 450, 14, 1],\n",
       " [62, 5, 133, 9, 119, 5, 1, 957, 1, 119, 5, 1],\n",
       " [14, 129, 611, 1354, 14, 2],\n",
       " [81, 242, 48, 49, 140, 129, 38, 35, 1251, 30],\n",
       " [1, 17, 1072, 1437, 1154, 108, 615, 62, 19, 3106, 2],\n",
       " [1345, 2],\n",
       " [560, 1475, 30],\n",
       " [1, 24, 52, 75, 88],\n",
       " [649, 4, 3, 3770, 1, 26, 140, 3, 3730],\n",
       " [10, 11],\n",
       " [130, 85, 82, 897, 568, 1600, 40, 150, 638, 7062, 1746, 211, 3107, 547, 126],\n",
       " [3771, 2683, 1892, 7063, 3065, 338, 7064, 858, 7065, 991, 2684, 4],\n",
       " [9, 4837, 245, 72, 405, 245, 405, 388, 1162, 359, 72, 10, 4, 122],\n",
       " [15, 9, 1847, 549, 7, 2],\n",
       " [217, 56],\n",
       " [81, 1747, 18, 1893, 4, 183, 1432, 3070, 1748],\n",
       " [378, 54, 1],\n",
       " [917, 180, 31, 68, 255, 7066],\n",
       " [3, 36, 202, 948, 226, 1, 163],\n",
       " [1, 8, 4838, 1749, 749],\n",
       " [3772, 75, 265, 3108],\n",
       " [276, 84, 1, 225, 37, 2099],\n",
       " [1073, 7067, 295, 1001, 513, 18, 358, 71, 1894, 3770, 2062, 17],\n",
       " [1575, 1, 350],\n",
       " [2100, 305, 291, 1693, 373, 31, 2312, 1704, 3, 57, 4, 133, 112, 4839],\n",
       " [1074,\n",
       "  704,\n",
       "  7068,\n",
       "  592,\n",
       "  13,\n",
       "  440,\n",
       "  7069,\n",
       "  288,\n",
       "  719,\n",
       "  28,\n",
       "  273,\n",
       "  244,\n",
       "  3048,\n",
       "  25,\n",
       "  719,\n",
       "  121],\n",
       " [1, 167, 124, 38, 135],\n",
       " [997, 137, 4840, 2, 426, 327],\n",
       " [82, 47, 95, 165, 511, 15, 1011, 73, 1, 3095, 489],\n",
       " [371, 6, 27, 2, 210, 414, 87],\n",
       " [5, 3773, 158, 612, 427, 5, 4, 3774, 2101],\n",
       " [1075, 796, 180, 1],\n",
       " [368, 1, 211, 1684],\n",
       " [513, 1, 8],\n",
       " [1895, 518, 427, 3109, 2084],\n",
       " [1, 14, 13],\n",
       " [9, 170, 18, 26, 239, 1],\n",
       " [2],\n",
       " [958, 76, 158, 1750],\n",
       " [149, 4, 6, 44, 11, 149, 15, 7070, 13],\n",
       " [1355, 4841, 7071, 58, 370, 93, 1076, 79, 615, 1601, 79, 476],\n",
       " [878, 508, 10, 3110, 126, 134, 16, 121, 2, 187],\n",
       " [627, 1125, 47, 4842, 29, 3775, 11],\n",
       " [299, 30],\n",
       " [523, 1751, 11, 84, 25, 1000, 7072, 7073, 7074, 158, 2685, 7075, 254, 738],\n",
       " [397, 1896, 139, 137, 4843, 49],\n",
       " [20, 1, 608, 7076, 1435],\n",
       " [3111, 101, 7077, 7, 1],\n",
       " [36, 53, 1, 120, 45, 466],\n",
       " [88, 7, 2],\n",
       " [3112, 40, 4844, 1185, 22, 1, 1239],\n",
       " [402, 217, 1009, 254, 167],\n",
       " [696, 2334, 4],\n",
       " [441, 1, 7078, 1897, 279, 5],\n",
       " [2],\n",
       " [29, 4, 7079, 598, 182, 1602, 331, 2, 136, 7080, 99, 8, 142],\n",
       " [7081, 4845, 359, 585, 4846, 244, 1073, 7082],\n",
       " [217, 2672, 754],\n",
       " [1],\n",
       " [2282, 3, 1, 124, 7083, 35, 1265, 12],\n",
       " [3776, 1, 7084, 416],\n",
       " [7085, 1254, 24, 58, 1, 2040, 2354, 1476, 8, 1603],\n",
       " [402, 2355, 2355, 2355, 4847, 19, 9, 113, 1266, 105, 3777],\n",
       " [2, 176, 5, 918, 19, 31, 154],\n",
       " [33, 7086, 93, 1],\n",
       " [204, 54, 941, 129, 3, 7, 143, 7087, 15, 7088, 14],\n",
       " [1, 47, 269, 106, 1, 643, 553, 594],\n",
       " [148, 1],\n",
       " [735, 222, 23, 8, 650, 1752, 3113, 1015, 35, 94, 122],\n",
       " [30],\n",
       " [2102, 2, 1, 8, 3688, 1704, 10, 3],\n",
       " [832, 2, 86, 96, 51, 323, 408, 69, 1, 26, 3, 408],\n",
       " [59, 382, 7089, 1477, 1898, 14, 1, 234, 3, 22, 81, 224],\n",
       " [7090, 1335, 1690, 7091, 352, 3114, 452],\n",
       " [535, 9, 664, 2, 56, 535, 256, 664, 576],\n",
       " [79, 732],\n",
       " [28, 4848, 1, 9, 7092],\n",
       " [9, 2103, 396, 959, 7093, 660, 1],\n",
       " [4849],\n",
       " [1604, 44, 40, 1899, 381, 7094, 1873, 135, 285, 61, 1900],\n",
       " [1605, 169, 1901, 49, 1],\n",
       " [9, 1],\n",
       " [1072, 41, 6, 1606, 1688, 10, 797, 24, 24, 442, 4, 1688],\n",
       " [17, 2],\n",
       " [36],\n",
       " [53, 3115, 7095, 68, 4850, 960, 1186, 11, 7, 9],\n",
       " [4851, 7096, 117, 61, 37, 7097, 7098, 1902, 56, 7099, 7100],\n",
       " [3778, 4852, 7101, 1718, 335, 3116, 54, 3779, 7102, 1],\n",
       " [302, 205, 1, 302, 205, 5],\n",
       " [161, 98, 3, 416, 3, 2, 116, 210, 1077, 199, 145],\n",
       " [21, 7103, 7104, 2, 686],\n",
       " [2, 280, 9, 2, 31],\n",
       " [9, 859, 17, 30],\n",
       " [131, 245, 1178, 311, 320, 153],\n",
       " [1478, 1, 224, 6, 1753, 1, 303, 487, 4853, 7105, 4854],\n",
       " [9, 1479, 3117, 9, 145, 9, 271, 50, 4855, 20, 63, 220, 919, 125],\n",
       " [1, 250, 12],\n",
       " [17, 23, 3780, 348],\n",
       " [24, 91, 102, 289, 3118, 7106, 4],\n",
       " [57, 1, 7107],\n",
       " [258, 1, 2327, 3119],\n",
       " [111, 3120, 3781, 2356, 3121, 833, 157],\n",
       " [8, 363, 521, 1, 1607, 19, 7108, 282, 85],\n",
       " [93, 84, 135, 557, 128, 4856, 4857, 591, 27, 169, 4856],\n",
       " [4],\n",
       " [170, 662, 107, 4, 5, 8, 406],\n",
       " [7109, 114, 234, 1187, 38],\n",
       " [206, 71, 3122, 224, 3, 54, 125, 62, 279, 31],\n",
       " [130, 493, 776, 761, 599, 275, 1070, 1181, 1596],\n",
       " [1320, 6, 1333, 7110, 3058, 672, 2357, 374, 74, 3782, 12],\n",
       " [84, 3, 27, 9, 1, 533, 798, 334, 1, 37, 17, 1, 15, 13, 1],\n",
       " [2358, 1, 2],\n",
       " [250, 37, 961, 4858, 646, 4859, 31, 1188, 323, 14, 613, 2104],\n",
       " [390, 5, 122, 3783, 119, 2, 461],\n",
       " [167, 1, 440],\n",
       " [1, 13, 408, 13, 920],\n",
       " [2, 8, 881, 7111],\n",
       " [574, 74, 757, 862, 50, 2356, 3123],\n",
       " [2105, 1608, 30],\n",
       " [24, 61, 17],\n",
       " [2, 37, 112, 123, 186, 10, 34, 116],\n",
       " [485, 2, 2359, 2, 873],\n",
       " [1863, 69, 9, 1, 220, 4860, 5, 224, 201, 335, 1],\n",
       " [5, 6, 153, 2, 466],\n",
       " [34, 3124, 1695, 39, 3784, 1466, 2106, 536, 30, 211, 118, 644, 7112],\n",
       " [2107, 4861, 342, 2, 383, 12],\n",
       " [220, 218, 2686, 218, 21, 823, 295],\n",
       " [169, 50, 165, 2687, 2360, 12, 493, 2293, 7113],\n",
       " [73, 1],\n",
       " [1, 69, 35, 2359, 36, 53, 17, 2359],\n",
       " [205, 2, 12, 834, 32, 84, 60, 19, 124, 414],\n",
       " [4862, 75, 4, 400, 1126, 224, 41, 385, 651, 3785, 4863],\n",
       " [4864, 200],\n",
       " [5, 2361, 3, 1, 294, 1754, 5, 87, 414],\n",
       " [2362, 1, 111, 10],\n",
       " [39, 92, 424, 91, 814, 1, 92, 424, 15, 3, 345, 63],\n",
       " [53, 1, 5],\n",
       " [2, 70, 13, 48, 3786, 274, 124, 325],\n",
       " [7114, 187, 617, 1],\n",
       " [4, 624, 835, 378],\n",
       " [33, 40, 2688, 7115, 1755, 789, 106, 165, 762, 58, 4],\n",
       " [7116, 4865, 438, 4],\n",
       " [90, 10, 1756, 161, 1116, 95, 987, 301, 882, 1, 615, 7117, 40],\n",
       " [46, 1, 338, 1356, 15, 793, 91, 1015, 2088],\n",
       " [1, 197, 3787, 124, 120],\n",
       " [225, 1009, 2],\n",
       " [12, 27, 1, 2363, 1757, 1267],\n",
       " [23, 828, 2364, 7118, 2, 104, 2, 869, 78, 869, 16, 950, 950],\n",
       " [14, 613, 246, 68, 91, 1226, 1256, 3788, 54, 225, 1189, 275],\n",
       " [199, 3, 4866, 3789, 404, 1, 184],\n",
       " [1, 49, 2689, 96],\n",
       " [36, 3052, 7119, 7120, 782, 11, 7121, 4867, 518, 1578, 7122, 4868],\n",
       " [4677, 2999, 4678, 3, 989, 3657, 4679, 372, 4681, 2025, 3000, 306],\n",
       " [4797, 4869, 4869, 4870, 7123, 770, 770, 1701, 770, 1046, 7124],\n",
       " [1268, 1, 2108, 1609, 453, 223, 36, 1903],\n",
       " [131, 1849, 7125, 306],\n",
       " [187, 80, 187, 1, 187, 49, 10, 7126],\n",
       " [1610, 1, 2107],\n",
       " [429, 33, 71, 614],\n",
       " [1, 1329, 125, 62, 260],\n",
       " [331, 1, 586, 173],\n",
       " [124, 85, 49, 119, 453, 3, 2, 4792],\n",
       " [1248, 2690, 2109, 1892, 93, 78, 43, 61, 294, 6, 323, 636],\n",
       " [1611, 1479, 120, 77, 16, 173, 4871, 600],\n",
       " [25, 549, 2],\n",
       " [2365, 962, 1004, 70, 534, 71, 350, 2691, 739],\n",
       " [1263, 128, 193, 836, 7127, 1248],\n",
       " [1269, 2, 110, 1588],\n",
       " [102, 7, 3125, 255, 3, 3790, 7128, 1758, 18, 4872, 99, 26, 78, 21, 33, 1357],\n",
       " [245, 90, 335, 263, 7129, 428, 679, 350, 154, 46, 88, 1],\n",
       " [7130, 16, 337, 2],\n",
       " [418, 3, 7131, 511, 21, 50, 64, 199, 58, 4873, 103],\n",
       " [2692, 393, 285, 7132, 1],\n",
       " [26, 79, 115],\n",
       " [134, 5, 1190, 101, 3, 208, 757, 7, 329],\n",
       " [729, 1256, 720, 74, 4874, 7133, 4875, 584, 1233, 100, 218],\n",
       " [3791, 1480, 41, 566, 74, 74],\n",
       " [583, 3, 1, 1160, 7134, 1904, 875, 4876, 132],\n",
       " [9, 49, 1, 86, 104],\n",
       " [4, 7, 5],\n",
       " [53, 2, 26, 3, 7135],\n",
       " [1358, 619, 437, 837, 103],\n",
       " [1, 433, 6, 3126, 18, 921, 385, 684],\n",
       " [4877, 7136, 74, 3127, 183],\n",
       " [7137, 32, 781],\n",
       " [45, 662, 228, 3792, 7138, 7139, 7140, 1],\n",
       " [181, 49, 1759, 238, 1, 412, 1016, 343],\n",
       " [1078, 29, 1127, 719, 312, 177],\n",
       " [1853, 146, 1],\n",
       " [1, 166, 3, 487, 3, 178, 2061],\n",
       " [1270, 3128, 577, 7141, 646, 69, 586, 1],\n",
       " [254, 213],\n",
       " [2110, 3, 367, 2693, 1, 216, 4878, 309, 475, 159, 319],\n",
       " [787, 9, 375, 33, 1, 9, 408, 39, 39, 3, 57, 50, 1079, 1752],\n",
       " [18, 517, 16, 1017, 4879, 18, 67, 279, 9, 1105, 11],\n",
       " [2, 176],\n",
       " [14, 303, 29, 904, 29, 97, 98, 174, 97, 132, 1905, 7142, 1, 169, 904],\n",
       " [64],\n",
       " [2111, 11, 96, 5, 108, 5, 6, 7143, 1906],\n",
       " [215, 1481, 7144, 100],\n",
       " [32, 25, 109, 1, 4880],\n",
       " [11, 643],\n",
       " [1, 101, 7, 7145, 7, 1, 167, 3, 7146, 7, 956, 7147, 4881, 7, 1271, 118, 489],\n",
       " [78, 2694, 86, 1, 153, 27],\n",
       " [70, 95, 90, 2, 48, 763, 210, 2695, 144, 3129, 210, 63, 1866, 144, 2315],\n",
       " [302, 4882, 2, 436, 578, 1, 7, 377, 2696, 922],\n",
       " [1, 1047, 262, 3, 1482, 3004],\n",
       " [5, 222, 289, 1157, 2112, 3793, 56, 289, 228, 1612, 1],\n",
       " [690, 255, 3794],\n",
       " [601, 134, 670, 1],\n",
       " [7148, 183, 98, 3, 11],\n",
       " [1190, 1907, 61],\n",
       " [266, 13, 15, 266, 1, 18, 60, 10, 36, 58, 1760],\n",
       " [1, 523],\n",
       " [33, 1, 96, 10, 3, 945, 3, 1, 49, 208, 482, 2],\n",
       " [359, 3130, 7149, 2697, 7150, 542, 7151, 2615, 1613, 4883, 3795, 4884],\n",
       " [281],\n",
       " [426, 4, 18, 144, 118, 7152],\n",
       " [176, 4],\n",
       " [2113, 7153, 624, 11, 472, 3131, 4858, 75, 7154, 295, 3796],\n",
       " ...]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers returned above represents which words are present in each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18533, 50), (6178, 50))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build dictionary of words and their index\n",
    "word_index = tokenizer.word_index \n",
    "len(word_index)\n",
    "\n",
    "# Get top frequent words in train and test data sets\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "train_features = pad_sequences(train_sequences, maxlen=MAX_SEQ_LENGTH) \n",
    "test_features  = pad_sequences(test_sequences, maxlen=MAX_SEQ_LENGTH) \n",
    "train_features.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,   15,    6, 1543,    2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shallow NN: sklearn's MLPclassifier\n",
    "\n",
    "# Encoding labels for deep learning\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder() \n",
    "encoder.fit(train['label'])\n",
    "train_labels = encoder.transform(train['label'])\n",
    "test_labels = encoder.transform(test['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier(solver='adam', alpha=1e-5, learning_rate='adaptive', \n",
    "    early_stopping=True, activation = 'relu', hidden_layer_sizes=(512), \n",
    "    random_state=42)\n",
    "#Hidden layer with 512 nodes.\n",
    "model.fit(train_features, train_labels)\n",
    "predicted = model.predict(test_features)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[  50  985   11]\n",
      " [  87 4635   48]\n",
      " [   8  350    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.05      0.08      1046\n",
      "           1       0.78      0.97      0.86      4770\n",
      "           2       0.06      0.01      0.02       362\n",
      "\n",
      "    accuracy                           0.76      6178\n",
      "   macro avg       0.39      0.34      0.32      6178\n",
      "weighted avg       0.66      0.76      0.68      6178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print('Confusion Matrix:\\n', confusion_matrix(test_labels, predicted.round()))\n",
    "print(classification_report(test_labels, predicted.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add three layers instead of a single layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1046\n",
      "           1       0.77      1.00      0.87      4770\n",
      "           2       0.00      0.00      0.00       362\n",
      "\n",
      "    accuracy                           0.77      6178\n",
      "   macro avg       0.26      0.33      0.29      6178\n",
      "weighted avg       0.60      0.77      0.67      6178\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Deep NN with 3 layers: sklearn's MLPclassifier\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier(solver='adam', alpha=1e-5, learning_rate='adaptive', \n",
    "    early_stopping=True, activation = 'relu', hidden_layer_sizes=(512, 128, 12), \n",
    "    random_state=42)\n",
    "model.fit(train_features, train_labels)\n",
    "predicted = model.predict(test_features)\n",
    "predicted\n",
    "print(classification_report(test_labels, predicted.round()))\n",
    "# When you have insufficient data, you choice of classifier won't matter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Neural network peformed worst in this scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\krish\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 18533 samples, validate on 6178 samples\n",
      "Epoch 1/5\n",
      "18533/18533 [==============================] - 19s 1ms/step - loss: 0.4369 - acc: 0.8466 - val_loss: 0.3187 - val_acc: 0.8893\n",
      "Epoch 2/5\n",
      "18533/18533 [==============================] - 19s 1ms/step - loss: 0.3004 - acc: 0.8980 - val_loss: 0.2874 - val_acc: 0.8990\n",
      "Epoch 3/5\n",
      "18533/18533 [==============================] - 19s 1ms/step - loss: 0.2550 - acc: 0.9114 - val_loss: 0.2904 - val_acc: 0.9006\n",
      "Epoch 4/5\n",
      "18533/18533 [==============================] - 19s 1ms/step - loss: 0.2257 - acc: 0.9219 - val_loss: 0.2791 - val_acc: 0.9006\n",
      "Epoch 5/5\n",
      "18533/18533 [==============================] - 20s 1ms/step - loss: 0.1985 - acc: 0.9310 - val_loss: 0.2823 - val_acc: 0.9056\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.86      1046\n",
      "           1       0.93      0.96      0.94      4770\n",
      "           2       0.61      0.24      0.35       362\n",
      "\n",
      "   micro avg       0.91      0.90      0.90      6178\n",
      "   macro avg       0.80      0.69      0.72      6178\n",
      "weighted avg       0.90      0.90      0.89      6178\n",
      " samples avg       0.90      0.90      0.90      6178\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Deep NN with tensorflow keras\n",
    "import keras.utils\n",
    "# Keras requires categorical label classes\n",
    "# Hence, labels must be transformed from 0, 1, 2 to three dummy variables\n",
    "from keras.utils import to_categorical\n",
    "train_labels = to_categorical(np.asarray(train['label']))\n",
    "test_labels  = to_categorical(np.asarray(test['label']))\n",
    "train_labels.shape, test_labels.shape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dropout, Dense\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "model = Sequential()                                  # Build model\n",
    "#Adding embedding layers\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=MAX_SEQ_LENGTH))\n",
    "model.add(Dropout(0.5))                               # Input layer\n",
    "model.add(Flatten()) \n",
    "\n",
    "\n",
    "model.add(Dense(512, activation='relu'))              # Hidden layer 1\n",
    "model.add(Dense(128, activation='relu'))              # Hidden layer 2\n",
    "model.add(Dense(12, activation='relu'))               # Hidden layer 3\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))             # Output layer\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
    "\n",
    "#Three Layers of Neural network --->Input Layer,Hidden Layer and Output Layer\n",
    "model.fit(train_features, train_labels, batch_size=64, epochs=5,\n",
    "    validation_data=(test_features, test_labels))    # Train model\n",
    "\n",
    "predicted = model.predict(test_features)             # Evaluate model\n",
    "predicted\n",
    "print(classification_report(test_labels, predicted.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision and recall are pretty low for hate speech since we have very few rows in that category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[ 222  792   32]\n",
      " [ 876 3711  183]\n",
      " [  72  278   12]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.21      0.20      1046\n",
      "           1       0.78      0.78      0.78      4770\n",
      "           2       0.05      0.03      0.04       362\n",
      "\n",
      "    accuracy                           0.64      6178\n",
      "   macro avg       0.34      0.34      0.34      6178\n",
      "weighted avg       0.63      0.64      0.64      6178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder() \n",
    "encoder.fit(train['label'])\n",
    "train_labels = encoder.transform(train['label'])\n",
    "test_labels = encoder.transform(test['label'])\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "  \n",
    "def run_model(classifier, train_x, train_y, test_x, test_y):\n",
    "    classifier.fit(train_x, train_y)  \n",
    "    predict_y = classifier.predict(test_x)\n",
    "    print('Confusion Matrix:\\n', confusion_matrix(test_y, predict_y))\n",
    "    print('Classification Report:\\n', classification_report(test_y, predict_y))\n",
    "    return \n",
    "\n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "run_model(MultinomialNB(), train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\krish\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\krish\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\krish\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[  12 1034    0]\n",
      " [  48 4722    0]\n",
      " [   7  355    0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.01      0.02      1046\n",
      "           1       0.77      0.99      0.87      4770\n",
      "           2       0.00      0.00      0.00       362\n",
      "\n",
      "    accuracy                           0.77      6178\n",
      "   macro avg       0.32      0.33      0.30      6178\n",
      "weighted avg       0.63      0.77      0.67      6178\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  82  956    8]\n",
      " [ 384 4349   37]\n",
      " [  33  324    5]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.08      0.11      1046\n",
      "           1       0.77      0.91      0.84      4770\n",
      "           2       0.10      0.01      0.02       362\n",
      "\n",
      "    accuracy                           0.72      6178\n",
      "   macro avg       0.35      0.33      0.32      6178\n",
      "weighted avg       0.63      0.72      0.67      6178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression & Stochastic Gradient Descent\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "run_model(LogisticRegression(), train_features, train_labels, test_features, test_labels)\n",
    "run_model(SGDClassifier(), train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[ 487  391  168]\n",
      " [1661 2550  559]\n",
      " [ 117  190   55]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.47      0.29      1046\n",
      "           1       0.81      0.53      0.65      4770\n",
      "           2       0.07      0.15      0.10       362\n",
      "\n",
      "    accuracy                           0.50      6178\n",
      "   macro avg       0.37      0.38      0.35      6178\n",
      "weighted avg       0.67      0.50      0.55      6178\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "from sklearn.svm import LinearSVC\n",
    "run_model(LinearSVC(), train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[ 602  430   14]\n",
      " [ 245 4490   35]\n",
      " [  59  276   27]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.58      0.62      1046\n",
      "           1       0.86      0.94      0.90      4770\n",
      "           2       0.36      0.07      0.12       362\n",
      "\n",
      "    accuracy                           0.83      6178\n",
      "   macro avg       0.63      0.53      0.55      6178\n",
      "weighted avg       0.80      0.83      0.81      6178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest (Bagging Model)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "run_model(RandomForestClassifier(), train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[ 753  289    4]\n",
      " [ 197 4540   33]\n",
      " [  53  272   37]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.72      0.73      1046\n",
      "           1       0.89      0.95      0.92      4770\n",
      "           2       0.50      0.10      0.17       362\n",
      "\n",
      "    accuracy                           0.86      6178\n",
      "   macro avg       0.71      0.59      0.61      6178\n",
      "weighted avg       0.84      0.86      0.84      6178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost (Boosting Model)\n",
    "# pip install xgboost\n",
    "from xgboost import XGBClassifier\n",
    "run_model(XGBClassifier(), train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_labels = to_categorical(np.asarray(train['label']))\n",
    "test_labels  = to_categorical(np.asarray(test['label']))\n",
    "# Convolutional Neural Network: ConvID\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dropout, Conv1D, MaxPooling1D\n",
    "from keras.layers import BatchNormalization, Flatten, Dense\n",
    "\n",
    "model = Sequential()                                # Build model\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=MAX_SEQ_LENGTH))\n",
    "model.add(Dropout(0.5))                             # Input layer\n",
    "\n",
    "#Convulational layers used to reduce number of features\n",
    "model.add(Conv1D(128, 5, activation='relu'))        # Convolutional layer 1\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv1D(128, 5, activation='relu'))        # Convolutional layer 2\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())                     \n",
    "model.add(Dense(128, activation='relu'))            # Hidden layer\n",
    "model.add(Dense(3, activation='softmax'))           # Output layer\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18533 samples, validate on 6178 samples\n",
      "Epoch 1/5\n",
      "18533/18533 [==============================] - 18s 964us/step - loss: 0.6638 - acc: 0.7633 - val_loss: 0.6107 - val_acc: 0.7757\n",
      "Epoch 2/5\n",
      "18533/18533 [==============================] - 17s 899us/step - loss: 0.4898 - acc: 0.8163 - val_loss: 0.4855 - val_acc: 0.8357\n",
      "Epoch 3/5\n",
      "18533/18533 [==============================] - 18s 965us/step - loss: 0.4305 - acc: 0.8558 - val_loss: 0.4292 - val_acc: 0.8534\n",
      "Epoch 4/5\n",
      "18533/18533 [==============================] - 18s 965us/step - loss: 0.4042 - acc: 0.8689 - val_loss: 0.4141 - val_acc: 0.8561\n",
      "Epoch 5/5\n",
      "18533/18533 [==============================] - 18s 972us/step - loss: 0.3842 - acc: 0.8791 - val_loss: 0.4141 - val_acc: 0.8555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1ee1d2c22c8>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_features, train_labels, batch_size=64, epochs=5,\n",
    "    validation_data=(test_features, test_labels))       # Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.63      0.70      1038\n",
      "           1       0.88      0.96      0.92      4792\n",
      "           2       0.00      0.00      0.00       348\n",
      "\n",
      "   micro avg       0.86      0.85      0.86      6178\n",
      "   macro avg       0.55      0.53      0.54      6178\n",
      "weighted avg       0.81      0.85      0.83      6178\n",
      " samples avg       0.85      0.85      0.85      6178\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\krish\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(test_features)\n",
    "predicted\n",
    "print(classification_report(test_labels, predicted.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\krish\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 18533 samples, validate on 6178 samples\n",
      "Epoch 1/5\n",
      "18533/18533 [==============================] - 49s 3ms/step - loss: 0.2984 - accuracy: 0.9027 - val_loss: 0.2208 - val_accuracy: 0.9293\n",
      "Epoch 2/5\n",
      "18533/18533 [==============================] - 48s 3ms/step - loss: 0.1957 - accuracy: 0.9373 - val_loss: 0.2204 - val_accuracy: 0.9281\n",
      "Epoch 3/5\n",
      "18533/18533 [==============================] - 48s 3ms/step - loss: 0.1705 - accuracy: 0.9450 - val_loss: 0.2258 - val_accuracy: 0.9227\n",
      "Epoch 4/5\n",
      "18533/18533 [==============================] - 49s 3ms/step - loss: 0.1567 - accuracy: 0.9496 - val_loss: 0.2338 - val_accuracy: 0.9209\n",
      "Epoch 5/5\n",
      "18533/18533 [==============================] - 48s 3ms/step - loss: 0.1418 - accuracy: 0.9558 - val_loss: 0.2507 - val_accuracy: 0.9141\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.72      0.74      1038\n",
      "           1       0.92      0.94      0.93      4792\n",
      "           2       0.27      0.05      0.09       348\n",
      "\n",
      "   micro avg       0.88      0.86      0.87      6178\n",
      "   macro avg       0.65      0.57      0.59      6178\n",
      "weighted avg       0.85      0.86      0.85      6178\n",
      " samples avg       0.86      0.86      0.86      6178\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Recurrent Neural Network: SimpleRNN\n",
    "\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=MAX_SEQ_LENGTH)) #Sequential layer\n",
    "model.add(SimpleRNN(2, input_shape=(None,1)))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_features, train_labels, batch_size=16, epochs=5,\n",
    "          validation_data=(test_features, test_labels))\n",
    "\n",
    "predicted = model.predict(test_features)\n",
    "predicted\n",
    "print(classification_report(test_labels, predicted.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(activation=\"relu\", return_sequences=True, units=16, recurrent_activation=\"hard_sigmoid\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18533 samples, validate on 6178 samples\n",
      "Epoch 1/3\n",
      "18533/18533 [==============================] - 80s 4ms/step - loss: 0.2237 - accuracy: 0.9133 - val_loss: 0.1746 - val_accuracy: 0.9353\n",
      "Epoch 2/3\n",
      "18533/18533 [==============================] - 76s 4ms/step - loss: 0.1383 - accuracy: 0.9479 - val_loss: 0.1972 - val_accuracy: 0.9338\n",
      "Epoch 3/3\n",
      "18533/18533 [==============================] - 83s 4ms/step - loss: 0.0888 - accuracy: 0.9678 - val_loss: 0.2473 - val_accuracy: 0.9226\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.74      0.80      1038\n",
      "           1       0.91      0.96      0.93      4792\n",
      "           2       0.40      0.19      0.26       348\n",
      "\n",
      "   micro avg       0.89      0.88      0.88      6178\n",
      "   macro avg       0.72      0.63      0.66      6178\n",
      "weighted avg       0.87      0.88      0.87      6178\n",
      " samples avg       0.88      0.88      0.88      6178\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# RNN: LSTM\n",
    "\n",
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=MAX_SEQ_LENGTH))\n",
    "model.add(LSTM(output_dim=16, activation='relu', \n",
    "               inner_activation='hard_sigmoid',return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_features, train_labels, batch_size=16, epochs=3,\n",
    "          validation_data=(test_features, test_labels))\n",
    "\n",
    "predicted = model.predict(test_features)\n",
    "predicted\n",
    "print(classification_report(test_labels, predicted.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18533 samples, validate on 6178 samples\n",
      "Epoch 1/3\n",
      "18533/18533 [==============================] - 90s 5ms/step - loss: 0.2277 - accuracy: 0.9121 - val_loss: 0.1729 - val_accuracy: 0.9358\n",
      "Epoch 2/3\n",
      "18533/18533 [==============================] - 86s 5ms/step - loss: 0.1362 - accuracy: 0.9494 - val_loss: 0.1797 - val_accuracy: 0.9349\n",
      "Epoch 3/3\n",
      "18533/18533 [==============================] - 85s 5ms/step - loss: 0.0864 - accuracy: 0.9680 - val_loss: 0.2175 - val_accuracy: 0.9333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84      1038\n",
      "           1       0.93      0.96      0.94      4792\n",
      "           2       0.56      0.20      0.30       348\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      6178\n",
      "   macro avg       0.78      0.67      0.69      6178\n",
      "weighted avg       0.89      0.90      0.89      6178\n",
      " samples avg       0.90      0.90      0.90      6178\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# RNN: Bidirectional LSTM\n",
    "\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=MAX_SEQ_LENGTH))\n",
    "model.add(Bidirectional(LSTM(16, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)))\n",
    "model.add(Conv1D(16, kernel_size=3, padding=\"valid\", kernel_initializer=\"glorot_uniform\"))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(50, activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_features, train_labels, batch_size=16, epochs=3,\n",
    "          validation_data=(test_features, test_labels))\n",
    "\n",
    "predicted = model.predict(test_features)\n",
    "predicted\n",
    "print(classification_report(test_labels, predicted.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
